# Single entry configuration (meta-repo).
#
# This file is the canonical entry point for running the whole pipeline:
# - AutoSHUD Step1–Step3 (static inputs, baseline forcing CSV if enabled)
# - SHUD run (baseline CSV forcing today; NetCDF forcing + NetCDF output later)
#
# Tooling: `python3 tools/shudnc.py projects/qhh/shud.yaml ...`

project:
  name: qhh
  title: "QHH official example"

paths:
  autoshud_dir: AutoSHUD
  shud_bin: SHUD/shud

time:
  # AutoSHUD expects year range + day indices (STARTDAY/ENDDAY). Keep them explicit for now.
  start_year: 2017
  end_year: 2018
  start_day: 1
  end_day: 730

spatial:
  # Inputs used by AutoSHUD Step1 (not committed to GitHub).
  wbd: Data/projects/qhh/raw/spatial/meritbasin_wbd1_32647.shp
  stm: Data/projects/qhh/raw/spatial/meritbasin_riv1.shp
  dem: Data/projects/qhh/raw/spatial/gdem.tif
  lake: Data/projects/qhh/raw/spatial/Lake.shp # optional; remove if you don't have it

datasets:
  soil:
    # Global soil mode (<1). 0.1 = HWSD.
    code: 0.1
    dir: Data/Soil/HWSD_RASTER

  landuse:
    # Global landuse mode (<1). 0.1 = USGS LCI.
    code: 0.1
    file: Data/Landuse/USGS_LCI/LCType.tif

autoshud:
  parameters:
    NumCells: 3000
    AqDepth: 8
    MaxArea_km2: 20
    MinAngle: 30
    tol_wb: 1000
    tol_rivlen: 3000
    RivWidth: 10
    RivDepth: 6
    DistBuffer_m: 2000
    flowpath: 0
    QuickMode: 0
    MAX_SOLVER_STEP: 6
    CRYOSPHERE: 0

profiles:
  # Baseline: original AutoSHUD -> SHUD workflow (generates forcing CSV).
  baseline:
    run_dir: runs/qhh/baseline
    autoshud:
      steps: [1, 2, 3]
      forcing:
        # AutoSHUD forcing code: 0.5 = CMFD.
        code: 0.5
        dir_ldas: Data/Forcing/CMFD2
        csv_dir: runs/qhh/baseline/forcing
    shud:
      run: true
      forcing_mode: csv
      output_mode: legacy

  # Baseline (CSV): ERA5 at the same forcing stations as `baseline` (for regression vs NetCDF ERA5).
  era5_baseline:
    run_dir: runs/qhh/era5_baseline
    autoshud:
      # Intentionally empty by default: we reuse existing Step1–Step3 static inputs and
      # generate forcing CSV via tooling (see tools/gen_forcing_baseline.py).
      steps: []
      forcing:
        # AutoSHUD does not natively support ERA5 yet (reserved code for future).
        code: 0.7
        dir_ldas: Data/Forcing/ERA5
        csv_dir: runs/qhh/era5_baseline/forcing
    shud:
      run: true
      forcing_mode: csv
      output_mode: legacy

  # Baseline (CSV): GLDAS at the same forcing stations as `baseline` (for regression vs NetCDF GLDAS).
  gldas_baseline:
    run_dir: runs/qhh/gldas_baseline
    autoshud:
      # Intentionally empty by default: we reuse existing Step1–Step3 static inputs and
      # generate forcing CSV via tooling (see tools/gen_forcing_baseline.py).
      steps: []
      forcing:
        # AutoSHUD forcing code: 0.3 = GLDAS.
        code: 0.3
        dir_ldas: Data/Forcing/GLDAS
        csv_dir: runs/qhh/gldas_baseline/forcing
    shud:
      run: true
      forcing_mode: csv
      output_mode: legacy

  # Target (future): SHUD reads forcing NetCDF + writes output NetCDF.
  nc:
    run_dir: runs/qhh/nc
    shud:
      run: false
      forcing_mode: netcdf
      forcing:
        product: cmfd2
        dir: Data/Forcing/CMFD2
        adapter: configs/forcing/cmfd2.yaml
        kv:
          # Compatibility override: match the existing baseline forcing CSV
          # (which was generated assuming precip is mm/hr and converting via *24).
          CMFD_PRECIP_UNITS: MM_HR
        # Switch to ERA5 (QHH subset example):
        # product: era5
        # dir: Data/Forcing/ERA5
        # adapter: configs/forcing/era5.yaml
        # Switch to GLDAS (global 0.25deg, 3-hour, one file per timestep):
        # product: gldas
        # dir: Data/Forcing/GLDAS
        # adapter: configs/forcing/gldas.yaml
      output_mode: legacy
      output:
        schema: configs/output/ugrid.yaml
        dir: runs/qhh/nc/output_netcdf
